{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd1223-46d3-46ed-985d-2f6ebeeb3348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/ygtxr1997/CelebBasis/main/infer_images/wiki_names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2e751-760f-4871-8005-a7aa248dc64f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/ygtxr1997/CelebBasis/main/infer_images/celebs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b27f2-0334-4c4a-9a69-318b6e894bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#with Path('wiki_names.txt').open() as f:\n",
    "with Path('celebs.txt').open() as f:\n",
    "    wiki_names = f.read().split('\\n')\n",
    "\n",
    "len(wiki_names) # 1109\n",
    "\n",
    "first_names = [n for n in set([name.split(' ')[0] for name in wiki_names]) if '.' not in n]\n",
    "last_names = [n for n in set([name.split(' ')[-1] for name in wiki_names]) if '.' not in n]\n",
    "\n",
    "len(first_names), len(last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e652abc7-fa0e-4e9d-839e-779863dcf3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83084e4e-d174-4683-a2e7-915573235035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef246ad9-fc70-478d-871d-8a3c1f8798d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "                model_id,\n",
    "                revision=\"fp16\",\n",
    "                #torch_dtype=torch.float16,\n",
    "                #use_auth_token=True\n",
    "            ).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20716c2b-585e-4efc-a9cf-9c77f2a910c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\"diffusers\",\n",
    "#    \"EulerDiscreteScheduler\"\n",
    "#pipe.scheduler\n",
    "import diffusers\n",
    "#pipe.scheduler = diffusers.EulerDiscreteScheduler()\n",
    "# https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/scheduler/scheduler_config.json\n",
    "true, false, null = True, False, None\n",
    "pipe.scheduler = diffusers.EulerDiscreteScheduler(\n",
    "    **{\n",
    "      #\"_class_name\": \"EulerDiscreteScheduler\",\n",
    "      #\"_diffusers_version\": \"0.19.0.dev0\",\n",
    "      \"beta_end\": 0.012,\n",
    "      \"beta_schedule\": \"scaled_linear\",\n",
    "      \"beta_start\": 0.00085,\n",
    "      #\"clip_sample\": false,\n",
    "      \"interpolation_type\": \"linear\",\n",
    "      \"num_train_timesteps\": 1000,\n",
    "      \"prediction_type\": \"epsilon\",\n",
    "      #\"sample_max_value\": 1.0,\n",
    "      #\"set_alpha_to_one\": false,\n",
    "      #\"skip_prk_steps\": true,\n",
    "      \"steps_offset\": 1,\n",
    "      \"timestep_spacing\": \"leading\",\n",
    "      \"trained_betas\": null,\n",
    "      \"use_karras_sigmas\": false\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b8981-1430-4fe0-87ba-a03cedfded10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diffusers.EulerDiscreteScheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dbb6fe-3fa4-4ce0-80cf-afff271f04c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    num_inference_steps=25,\n",
    "    num_images_per_prompt=1,\n",
    "    \n",
    ")\n",
    "prompt = \"a painting of an apple\"\n",
    "outv = pipe(prompt, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba57c5-0efb-4309-814a-f4cf03afbb31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outv.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e17bd-ef9f-4afc-aa6d-b568de2fad49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. loop over names\n",
    "# 2. create folder for names\n",
    "# 3. generate images, save to folder\n",
    "# 4. compute CLIP/DINO image embeddings, save to folder\n",
    "\n",
    "# ---\n",
    "\n",
    "# let's start with 10 names and prototype this procedure generally.\n",
    "# an important hyper parameter to start with will be the number of images per name.\n",
    "# let's start by generating an unnecessary number of images for this first group, say 20-100.\n",
    "# then use these to compute our diversity measures, and calibrate how many images we need by how many images it generally takes to get this measure to converge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1027ae70-87bb-434e-8f14-991ce7086d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pipe.requires_safety_checker=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab912e2-a67c-4616-bfb4-8785c033e9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def passthrough(images, *args, **kargs):\n",
    "    return images, [False for _ in images]\n",
    "pipe.safety_checker = passthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80112b91-0163-4af8-8ddb-ca559d86c833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#names = [\"david\"] ## TODO: dev\n",
    "names = first_names\n",
    "\n",
    "kwargs = dict(\n",
    "    num_inference_steps=25,\n",
    "    num_images_per_prompt=8\n",
    ")\n",
    "\n",
    "root = Path(\"images\")\n",
    "\n",
    "images_per_prompt = 24 #40\n",
    "\n",
    "for name in names:\n",
    "    #prompt = name\n",
    "    print(name)\n",
    "    prompt = f\"a photo of {name}, portrait photography, full color, face full frame\"\n",
    "    prompt = prompt.lower().strip()\n",
    "    \n",
    "    prompt_clean = prompt.replace(',','')\n",
    "    outdir = root / prompt_clean.replace(' ','_')  \n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    while len(list(outdir.glob('*.png'))) < images_per_prompt:\n",
    "        outv = pipe(prompt, **kwargs)\n",
    "        if any(outv.nsfw_content_detected):\n",
    "            #continue\n",
    "            break\n",
    "\n",
    "        for idx,im in enumerate(outv.images):\n",
    "            # would prefer to name images by seed, but hf is makes it hard.\n",
    "            fname = outdir / f\"{int(time.time())}_{idx}.png\" \n",
    "            im.save(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e60548-2fee-4af0-973b-68807e159a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's generate a shit load of images \n",
    "# for a few high-bias names as a calibration control\n",
    "# for sensitivity analysis.\n",
    "\n",
    "high_bias_names = [\n",
    "    \"oprah\",\n",
    "    \"keanu\",\n",
    "    \"cher\",\n",
    "    \"beyoncÃ©\",\n",
    "    \"shaquille\",\n",
    "    \"rihanna\",\n",
    "    \"anupam\",\n",
    "]\n",
    "\n",
    "images_per_prompt = 200\n",
    "\n",
    "\n",
    "for name in high_bias_names:\n",
    "    #prompt = name\n",
    "    print(name)\n",
    "    prompt = f\"a photo of {name}, portrait photography, full color, face full frame\"\n",
    "    prompt = prompt.lower().strip()\n",
    "    \n",
    "    prompt_clean = prompt.replace(',','')\n",
    "    outdir = root / prompt_clean.replace(' ','_')  \n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    while len(list(outdir.glob('*.png'))) < images_per_prompt:\n",
    "        outv = pipe(prompt, **kwargs)\n",
    "        if any(outv.nsfw_content_detected):\n",
    "            #continue\n",
    "            break\n",
    "\n",
    "        for idx,im in enumerate(outv.images):\n",
    "            # would prefer to name images by seed, but hf is makes it hard.\n",
    "            fname = outdir / f\"{int(time.time())}_{idx}.png\" \n",
    "            im.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab83c5fc-e79e-4ea6-8a3b-5196bd3eedc9",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* filtter out images with more than one face in them (check and report on what gets pulled out)\n",
    "* calibrate # images for experiments\n",
    "  * \"power analysis\" - how many images do we need to detect the variance threshold we're interested in?\"\n",
    "* DINOv2 embeddings\n",
    "* per-prompt (cluster) summary statistics\n",
    "* tSNE\n",
    "* separately generate and save input clip emberddings of prompts\n",
    "* score images relative to centroid in addition to summary statistic for cluster\n",
    "* repeat procedure across several checkpoints, compare per-cluster summary statistics across checkpoints. expect to observe narrowing of biases as checkpoints are progressively finetuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d4015-74f0-4fa0-8faf-a5936b01044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DINOv2 embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
